{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ramilopez99/RedNeuronal/blob/main/Red_neuronal_b%C3%A1sica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a4ndKMw9l272"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementación de la red neuronal con retropropagación"
      ],
      "metadata": {
        "id": "GgxPYawHone4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NetNode(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.inputs = []\n",
        "        self.weights = []\n",
        "        self.value = None"
      ],
      "metadata": {
        "id": "ayEcEwKcl_9H"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(object):\n",
        "\n",
        "    def __init__(self, layers):\n",
        "        self.net = [[NetNode() for _ in range(size)] for size in layers]\n",
        "        sizes = len(layers)\n",
        "        for layer in range(1, sizes):\n",
        "            for node in self.net[layer]:\n",
        "                for unit in self.net[layer - 1]:\n",
        "                    node.inputs.append(unit)\n",
        "                    node.weights.append(0)\n",
        "\n",
        "    def accuracy(self, examples):\n",
        "        correct = 0\n",
        "        for x_test, y_test in examples:\n",
        "            prediction = self.predict(x_test)\n",
        "            if (y_test[prediction] == 1):\n",
        "                correct += 1\n",
        "        return correct / len(examples)\n",
        "\n",
        "    def backpropagation(self, eta, examples, epochs):\n",
        "        inputs = self.net[0]\n",
        "        outputs = self.net[-1]\n",
        "        layer_size = len(self.net)\n",
        "        for layer in self.net[1:]:\n",
        "            for node in layer:\n",
        "                node.weights = [np.random.uniform() for _ in range(len(node.weights))]\n",
        "        for epoch in range(epochs):\n",
        "            for x_train, y_train in examples:\n",
        "                for value, node in zip(x_train, inputs):\n",
        "                    node.value = value\n",
        "                for layer in self.net[1:]:\n",
        "                    for node in layer:\n",
        "                        in_val = [n.value for n in node.inputs]\n",
        "                        unit_value = np.dot(in_val, node.weights)\n",
        "                        node.value = self.relu(unit_value)\n",
        "                delta = [[] for _ in range(layer_size)]\n",
        "                err = [y_train[i] - outputs[i].value for i in range(len(outputs))]\n",
        "                delta[-1] = [self.relu_prime(outputs[i].value) * err[i] for i in range(len(outputs))]\n",
        "                hidden_layers = layer_size - 2\n",
        "                for i in range(hidden_layers, 0, -1):\n",
        "                    layer = self.net[i]\n",
        "                    n_layers = len(layer)\n",
        "                    w = [[node.weights[l] for node in self.net[i + 1]] for l in range(n_layers)]\n",
        "                    delta[i] = [self.relu_prime(layer[j].value) * np.dot(w[j], delta[i + 1]) for j in range(n_layers)]\n",
        "                for i in range(1, layer_size):\n",
        "                    layer = self.net[i]\n",
        "                    in_val = [node.value for node in self.net[i - 1]]\n",
        "                    n_layers = len(self.net[i])\n",
        "                    for j in range(n_layers):\n",
        "                        layer[j].weights = np.add(layer[j].weights, np.multiply(eta * delta[i][j], in_val))\n",
        "            print(f\"epoch {epoch}/{epochs} | total error={np.sum(err)/len(examples)}\")\n",
        "    \n",
        "    def predict(self, input_data):\n",
        "        inputs = self.net[0]\n",
        "        for v, n in zip(input_data, inputs):\n",
        "            n.value = v\n",
        "        for layer in self.net[1:]:\n",
        "            for node in layer:\n",
        "                in_val = [n.value for n in node.inputs]\n",
        "                unit_value = np.dot(in_val, node.weights)\n",
        "                node.value = self.relu(unit_value)\n",
        "        outputs = self.net[-1]\n",
        "        return outputs.index(max(outputs, key=lambda node: node.value))\n",
        "\n",
        "    def relu(self, z):\n",
        "        return max(0, z)\n",
        "\n",
        "    def relu_prime(self, z):\n",
        "        return 1 if z > 0 else 0\n",
        "    \n",
        "    def weights(self):\n",
        "        weights = []\n",
        "        for layer in self.net:\n",
        "            for node in layer:\n",
        "                weights.append(node.weights)\n",
        "        return weights\n",
        "\n",
        "    def set_weights(self, weights):\n",
        "        if len(weights) != len(self.net):\n",
        "            raise ValueError(\"Número de capas no coincide\")\n",
        "        for i, layer in enumerate(weights):\n",
        "            if len(layer) != len(self.net[i]):\n",
        "                raise ValueError(\"Número de nodos en la capa no coincide\")\n",
        "            for j, node_weights in enumerate(layer):\n",
        "                if len(node_weights) != len(self.net[i][j].weights):\n",
        "                    raise ValueError(\"Número de pesos no coincide\")\n",
        "                self.net[i][j].weights = node_weights\n",
        "\n",
        "    def sigmoide(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def sigmoide_prime(self, z):\n",
        "        return self.sigmoide(z) * (1 - self.sigmoide(z))   "
      ],
      "metadata": {
        "id": "c76uCuQsmC3B"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Usando la red neuronal con un dataset"
      ],
      "metadata": {
        "id": "qgFoGWrqoyGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils"
      ],
      "metadata": {
        "id": "fPng_kT1mhcp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_X, iris_y = datasets.load_iris(return_X_y=True)"
      ],
      "metadata": {
        "id": "sFyU9RGtmluM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_x_normalized = normalize(iris_X, axis=0)"
      ],
      "metadata": {
        "id": "IQpaMM6Bmq1n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(iris_x_normalized, iris_y, test_size=0.2, shuffle=True)"
      ],
      "metadata": {
        "id": "OjQkFVwmmuGg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np_utils.to_categorical(y_train, num_classes=3)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes=3)"
      ],
      "metadata": {
        "id": "wvkyhxJTmyWo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = []\n",
        "for i in range(len(X_train)):\n",
        "    examples.append([X_train[i], y_train[i]])"
      ],
      "metadata": {
        "id": "-ZlXfw4xm2Ih"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Network([3, 4, 2])\n",
        "net.backpropagation(0.1, examples, 500)"
      ],
      "metadata": {
        "id": "x9YqtPo7m5Vq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeac7780-2120-42f5-f2c8-be0111a813a6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0/500 | total error=-0.006049978278837927\n",
            "epoch 1/500 | total error=-0.00583175601760354\n",
            "epoch 2/500 | total error=-0.005737640051134938\n",
            "epoch 3/500 | total error=-0.00565192041356933\n",
            "epoch 4/500 | total error=-0.005554889920505246\n",
            "epoch 5/500 | total error=-0.005440039440539093\n",
            "epoch 6/500 | total error=-0.005303780309974549\n",
            "epoch 7/500 | total error=-0.005213245631758918\n",
            "epoch 8/500 | total error=-0.005055746091273816\n",
            "epoch 9/500 | total error=-0.004863821770888109\n",
            "epoch 10/500 | total error=-0.004643727134313785\n",
            "epoch 11/500 | total error=-0.004413449072076619\n",
            "epoch 12/500 | total error=-0.004194497649241646\n",
            "epoch 13/500 | total error=-0.003956200631983914\n",
            "epoch 14/500 | total error=-0.00373927521577673\n",
            "epoch 15/500 | total error=-0.0035562492266229978\n",
            "epoch 16/500 | total error=-0.003418374788456816\n",
            "epoch 17/500 | total error=-0.0033385937203721907\n",
            "epoch 18/500 | total error=-0.0033595725082036245\n",
            "epoch 19/500 | total error=-0.00344642339284243\n",
            "epoch 20/500 | total error=-0.0035239952153022615\n",
            "epoch 21/500 | total error=-0.00359162826344267\n",
            "epoch 22/500 | total error=-0.0036532724285763393\n",
            "epoch 23/500 | total error=-0.0037088091930941526\n",
            "epoch 24/500 | total error=-0.003756884030351444\n",
            "epoch 25/500 | total error=-0.0037994957307483437\n",
            "epoch 26/500 | total error=-0.003833826555256714\n",
            "epoch 27/500 | total error=-0.003865281014874401\n",
            "epoch 28/500 | total error=-0.0038926739371230533\n",
            "epoch 29/500 | total error=-0.003916869220422144\n",
            "epoch 30/500 | total error=-0.003936663700099783\n",
            "epoch 31/500 | total error=-0.003951747959385112\n",
            "epoch 32/500 | total error=-0.003963026808279759\n",
            "epoch 33/500 | total error=-0.003973698475567878\n",
            "epoch 34/500 | total error=-0.003981714631038506\n",
            "epoch 35/500 | total error=-0.003990062516268429\n",
            "epoch 36/500 | total error=-0.003996228541818467\n",
            "epoch 37/500 | total error=-0.00400055036656679\n",
            "epoch 38/500 | total error=-0.004002763384185616\n",
            "epoch 39/500 | total error=-0.004004374420465501\n",
            "epoch 40/500 | total error=-0.0040074126105713636\n",
            "epoch 41/500 | total error=-0.0040113802637546485\n",
            "epoch 42/500 | total error=-0.004014231311825206\n",
            "epoch 43/500 | total error=-0.0040136015650972965\n",
            "epoch 44/500 | total error=-0.004014017405570648\n",
            "epoch 45/500 | total error=-0.004014261406936221\n",
            "epoch 46/500 | total error=-0.0040141092677884235\n",
            "epoch 47/500 | total error=-0.004017276507981979\n",
            "epoch 48/500 | total error=-0.004016119404031814\n",
            "epoch 49/500 | total error=-0.004016206423776031\n",
            "epoch 50/500 | total error=-0.004013622542090686\n",
            "epoch 51/500 | total error=-0.004014964165415263\n",
            "epoch 52/500 | total error=-0.004012020614585799\n",
            "epoch 53/500 | total error=-0.004013020889336556\n",
            "epoch 54/500 | total error=-0.004013998699701831\n",
            "epoch 55/500 | total error=-0.004009926298150604\n",
            "epoch 56/500 | total error=-0.004010294033325687\n",
            "epoch 57/500 | total error=-0.0040108525042395655\n",
            "epoch 58/500 | total error=-0.004005844177759339\n",
            "epoch 59/500 | total error=-0.004009969738636773\n",
            "epoch 60/500 | total error=-0.004004083058594087\n",
            "epoch 61/500 | total error=-0.004002011164099273\n",
            "epoch 62/500 | total error=-0.004000291484276369\n",
            "epoch 63/500 | total error=-0.003993112239925631\n",
            "epoch 64/500 | total error=-0.003991631444343833\n",
            "epoch 65/500 | total error=-0.003990548351713955\n",
            "epoch 66/500 | total error=-0.003989082467462106\n",
            "epoch 67/500 | total error=-0.003987188507315816\n",
            "epoch 68/500 | total error=-0.003984901396533722\n",
            "epoch 69/500 | total error=-0.003982393049701041\n",
            "epoch 70/500 | total error=-0.003979739608775628\n",
            "epoch 71/500 | total error=-0.00397696228939717\n",
            "epoch 72/500 | total error=-0.0039740707505463236\n",
            "epoch 73/500 | total error=-0.003981682404957743\n",
            "epoch 74/500 | total error=-0.003969553943585723\n",
            "epoch 75/500 | total error=-0.003965144233109956\n",
            "epoch 76/500 | total error=-0.00396164322258402\n",
            "epoch 77/500 | total error=-0.003958166870279772\n",
            "epoch 78/500 | total error=-0.003954599279445148\n",
            "epoch 79/500 | total error=-0.003950923056917283\n",
            "epoch 80/500 | total error=-0.00396030446349384\n",
            "epoch 81/500 | total error=-0.003945134991666411\n",
            "epoch 82/500 | total error=-0.003939672007315934\n",
            "epoch 83/500 | total error=-0.0039553778560386605\n",
            "epoch 84/500 | total error=-0.003932988103538828\n",
            "epoch 85/500 | total error=-0.003947877015210615\n",
            "epoch 86/500 | total error=-0.003946007304410287\n",
            "epoch 87/500 | total error=-0.003920012817092878\n",
            "epoch 88/500 | total error=-0.003935870857424631\n",
            "epoch 89/500 | total error=-0.0039336602925494285\n",
            "epoch 90/500 | total error=-0.003936085260185852\n",
            "epoch 91/500 | total error=-0.003931490105371355\n",
            "epoch 92/500 | total error=-0.003925004285777423\n",
            "epoch 93/500 | total error=-0.003918999271168298\n",
            "epoch 94/500 | total error=-0.003913284204648421\n",
            "epoch 95/500 | total error=-0.003907684463558773\n",
            "epoch 96/500 | total error=-0.0039020944861379403\n",
            "epoch 97/500 | total error=-0.003896428575099735\n",
            "epoch 98/500 | total error=-0.003890644853539705\n",
            "epoch 99/500 | total error=-0.0038847187124956065\n",
            "epoch 100/500 | total error=-0.003878627653124685\n",
            "epoch 101/500 | total error=-0.0038723549326937306\n",
            "epoch 102/500 | total error=-0.003865888242052055\n",
            "epoch 103/500 | total error=-0.003859146119757905\n",
            "epoch 104/500 | total error=-0.0038522020748784714\n",
            "epoch 105/500 | total error=-0.0038450555964207695\n",
            "epoch 106/500 | total error=-0.003837693982604863\n",
            "epoch 107/500 | total error=-0.003830067345911994\n",
            "epoch 108/500 | total error=-0.0038222152463417776\n",
            "epoch 109/500 | total error=-0.0038141339189312526\n",
            "epoch 110/500 | total error=-0.0038251408995648357\n",
            "epoch 111/500 | total error=-0.0038009737290465168\n",
            "epoch 112/500 | total error=-0.003809744026522175\n",
            "epoch 113/500 | total error=-0.003784582368007286\n",
            "epoch 114/500 | total error=-0.0037923195934254474\n",
            "epoch 115/500 | total error=-0.003766589145139411\n",
            "epoch 116/500 | total error=-0.003773501854246784\n",
            "epoch 117/500 | total error=-0.0037473670081127303\n",
            "epoch 118/500 | total error=-0.0037534467921981835\n",
            "epoch 119/500 | total error=-0.003745352201931977\n",
            "epoch 120/500 | total error=-0.003717609392649505\n",
            "epoch 121/500 | total error=-0.0037219465233629813\n",
            "epoch 122/500 | total error=-0.003712711480079329\n",
            "epoch 123/500 | total error=-0.0037020681912911624\n",
            "epoch 124/500 | total error=-0.003690793731721661\n",
            "epoch 125/500 | total error=-0.0036791018438028975\n",
            "epoch 126/500 | total error=-0.00366706583119507\n",
            "epoch 127/500 | total error=-0.0036547196355544032\n",
            "epoch 128/500 | total error=-0.003642057924415633\n",
            "epoch 129/500 | total error=-0.003628988643936112\n",
            "epoch 130/500 | total error=-0.0036156377247771893\n",
            "epoch 131/500 | total error=-0.00360199688388464\n",
            "epoch 132/500 | total error=-0.003588061971676762\n",
            "epoch 133/500 | total error=-0.0035632248875507393\n",
            "epoch 134/500 | total error=-0.0035556157698033095\n",
            "epoch 135/500 | total error=-0.003543271340807672\n",
            "epoch 136/500 | total error=-0.003529217451158981\n",
            "epoch 137/500 | total error=-0.0035143377518661797\n",
            "epoch 138/500 | total error=-0.0034989337073832606\n",
            "epoch 139/500 | total error=-0.0034727113037081882\n",
            "epoch 140/500 | total error=-0.0034638607887397146\n",
            "epoch 141/500 | total error=-0.003449770119432984\n",
            "epoch 142/500 | total error=-0.0034339461516289882\n",
            "epoch 143/500 | total error=-0.0034173032312481604\n",
            "epoch 144/500 | total error=-0.0033900729835823645\n",
            "epoch 145/500 | total error=-0.003380088246656611\n",
            "epoch 146/500 | total error=-0.0033644681984998305\n",
            "epoch 147/500 | total error=-0.0033471316580607176\n",
            "epoch 148/500 | total error=-0.0033281105204766253\n",
            "epoch 149/500 | total error=-0.003310052466916695\n",
            "epoch 150/500 | total error=-0.003300750431986822\n",
            "epoch 151/500 | total error=-0.003283278726240036\n",
            "epoch 152/500 | total error=-0.0032553328569260354\n",
            "epoch 153/500 | total error=-0.0032434182756139853\n",
            "epoch 154/500 | total error=-0.0032255764302447304\n",
            "epoch 155/500 | total error=-0.0032060544669643837\n",
            "epoch 156/500 | total error=-0.003177231656197492\n",
            "epoch 157/500 | total error=-0.0031641075221293734\n",
            "epoch 158/500 | total error=-0.003145287229861287\n",
            "epoch 159/500 | total error=-0.0031249448029094756\n",
            "epoch 160/500 | total error=-0.0030959257070480766\n",
            "epoch 161/500 | total error=-0.0030817313821812796\n",
            "epoch 162/500 | total error=-0.0030620960717308836\n",
            "epoch 163/500 | total error=-0.003035409814500615\n",
            "epoch 164/500 | total error=-0.0030215906961666246\n",
            "epoch 165/500 | total error=-0.003001664586467873\n",
            "epoch 166/500 | total error=-0.00298003252064187\n",
            "epoch 167/500 | total error=-0.0029506223564832617\n",
            "epoch 168/500 | total error=-0.0029359472022499025\n",
            "epoch 169/500 | total error=-0.0029151483879410692\n",
            "epoch 170/500 | total error=-0.002886179360510068\n",
            "epoch 171/500 | total error=-0.0028700882806770443\n",
            "epoch 172/500 | total error=-0.002848908762753893\n",
            "epoch 173/500 | total error=-0.00282077829861678\n",
            "epoch 174/500 | total error=-0.002810061524252905\n",
            "epoch 175/500 | total error=-0.0027837896353078402\n",
            "epoch 176/500 | total error=-0.002767999247500952\n",
            "epoch 177/500 | total error=-0.0027466974962416816\n",
            "epoch 178/500 | total error=-0.0027179794586610667\n",
            "epoch 179/500 | total error=-0.0027010357931594366\n",
            "epoch 180/500 | total error=-0.002679016673923886\n",
            "epoch 181/500 | total error=-0.002651314354962679\n",
            "epoch 182/500 | total error=-0.002633026993672752\n",
            "epoch 183/500 | total error=-0.0026105584383163873\n",
            "epoch 184/500 | total error=-0.0025838437055032398\n",
            "epoch 185/500 | total error=-0.0025651839945769962\n",
            "epoch 186/500 | total error=-0.0025428953489264354\n",
            "epoch 187/500 | total error=-0.0025155949532028542\n",
            "epoch 188/500 | total error=-0.002496615400993158\n",
            "epoch 189/500 | total error=-0.0024760184738456216\n",
            "epoch 190/500 | total error=-0.0024514549293939104\n",
            "epoch 191/500 | total error=-0.0024329459366593744\n",
            "epoch 192/500 | total error=-0.002410815690083091\n",
            "epoch 193/500 | total error=-0.0023848903310220186\n",
            "epoch 194/500 | total error=-0.0023654130515553375\n",
            "epoch 195/500 | total error=-0.002355448630144876\n",
            "epoch 196/500 | total error=-0.0023296180184305642\n",
            "epoch 197/500 | total error=-0.002309635174775037\n",
            "epoch 198/500 | total error=-0.0022903571968490503\n",
            "epoch 199/500 | total error=-0.002264234704932457\n",
            "epoch 200/500 | total error=-0.002245214925140453\n",
            "epoch 201/500 | total error=-0.0022226889715358396\n",
            "epoch 202/500 | total error=-0.0021961506052241057\n",
            "epoch 203/500 | total error=-0.002176902129016498\n",
            "epoch 204/500 | total error=-0.002154522627996306\n",
            "epoch 205/500 | total error=-0.002128328908818401\n",
            "epoch 206/500 | total error=-0.0021092597289745977\n",
            "epoch 207/500 | total error=-0.0020871540462831517\n",
            "epoch 208/500 | total error=-0.002064332264383137\n",
            "epoch 209/500 | total error=-0.002038295701300834\n",
            "epoch 210/500 | total error=-0.002019642258886059\n",
            "epoch 211/500 | total error=-0.0020145442498728954\n",
            "epoch 212/500 | total error=-0.0019918164609156203\n",
            "epoch 213/500 | total error=-0.0019736249193007416\n",
            "epoch 214/500 | total error=-0.0019517968091638854\n",
            "epoch 215/500 | total error=-0.0019256706340681745\n",
            "epoch 216/500 | total error=-0.0019078901537689802\n",
            "epoch 217/500 | total error=-0.0018893631573163267\n",
            "epoch 218/500 | total error=-0.0018675056655378624\n",
            "epoch 219/500 | total error=-0.0018421866655590224\n",
            "epoch 220/500 | total error=-0.0018243468801179546\n",
            "epoch 221/500 | total error=-0.00180330926420137\n",
            "epoch 222/500 | total error=-0.0017815305521476782\n",
            "epoch 223/500 | total error=-0.0017568758609233757\n",
            "epoch 224/500 | total error=-0.0017395960145763785\n",
            "epoch 225/500 | total error=-0.0017188380421958417\n",
            "epoch 226/500 | total error=-0.0016978470378316022\n",
            "epoch 227/500 | total error=-0.0016738448779026957\n",
            "epoch 228/500 | total error=-0.0016570046197302768\n",
            "epoch 229/500 | total error=-0.0016368953682295785\n",
            "epoch 230/500 | total error=-0.0016139774629050198\n",
            "epoch 231/500 | total error=-0.001597205433966987\n",
            "epoch 232/500 | total error=-0.0015779759510679708\n",
            "epoch 233/500 | total error=-0.0015577551534803789\n",
            "epoch 234/500 | total error=-0.0015353755957705727\n",
            "epoch 235/500 | total error=-0.0015191742967798137\n",
            "epoch 236/500 | total error=-0.001500362668741218\n",
            "epoch 237/500 | total error=-0.001478853931686752\n",
            "epoch 238/500 | total error=-0.0014631421149530889\n",
            "epoch 239/500 | total error=-0.001444808450639302\n",
            "epoch 240/500 | total error=-0.0014261399746755587\n",
            "epoch 241/500 | total error=-0.0014049245916230035\n",
            "epoch 242/500 | total error=-0.0013900118023444225\n",
            "epoch 243/500 | total error=-0.0013722208753337896\n",
            "epoch 244/500 | total error=-0.00135223360638155\n",
            "epoch 245/500 | total error=-0.0013371519074374158\n",
            "epoch 246/500 | total error=-0.0013197491278081207\n",
            "epoch 247/500 | total error=-0.0013006047011556658\n",
            "epoch 248/500 | total error=-0.0012857082195154759\n",
            "epoch 249/500 | total error=-0.001268829814266711\n",
            "epoch 250/500 | total error=-0.0012509820484060993\n",
            "epoch 251/500 | total error=-0.0012364153567796397\n",
            "epoch 252/500 | total error=-0.0012204666991419697\n",
            "epoch 253/500 | total error=-0.0012027922810716517\n",
            "epoch 254/500 | total error=-0.0011891573119802894\n",
            "epoch 255/500 | total error=-0.0011750663960551982\n",
            "epoch 256/500 | total error=-0.0011579209613649035\n",
            "epoch 257/500 | total error=-0.0011447324401686087\n",
            "epoch 258/500 | total error=-0.0011301592155017603\n",
            "epoch 259/500 | total error=-0.001114432914998386\n",
            "epoch 260/500 | total error=-0.0010984338722463613\n",
            "epoch 261/500 | total error=-0.001086057332749639\n",
            "epoch 262/500 | total error=-0.0010718526595107096\n",
            "epoch 263/500 | total error=-0.0010562382765304764\n",
            "epoch 264/500 | total error=-0.0010441440668381026\n",
            "epoch 265/500 | total error=-0.0010305562982945342\n",
            "epoch 266/500 | total error=-0.0010164804514696763\n",
            "epoch 267/500 | total error=-0.001001478576764272\n",
            "epoch 268/500 | total error=-0.0009899221293727801\n",
            "epoch 269/500 | total error=-0.0009774858540336228\n",
            "epoch 270/500 | total error=-0.000963538236193874\n",
            "epoch 271/500 | total error=-0.0009526855083832805\n",
            "epoch 272/500 | total error=-0.000940189310235977\n",
            "epoch 273/500 | total error=-0.0009274179154847317\n",
            "epoch 274/500 | total error=-0.0009136703829901269\n",
            "epoch 275/500 | total error=-0.0009032792162559781\n",
            "epoch 276/500 | total error=-0.0008914980120413961\n",
            "epoch 277/500 | total error=-0.0008783498326768908\n",
            "epoch 278/500 | total error=-0.0008685745671885929\n",
            "epoch 279/500 | total error=-0.0008572852087504186\n",
            "epoch 280/500 | total error=-0.0008455809480249515\n",
            "epoch 281/500 | total error=-0.0008323747772815119\n",
            "epoch 282/500 | total error=-0.0008231429941605617\n",
            "epoch 283/500 | total error=-0.000812410374947148\n",
            "epoch 284/500 | total error=-0.0007998559149024482\n",
            "epoch 285/500 | total error=-0.0007910204626899093\n",
            "epoch 286/500 | total error=-0.0007806644177537404\n",
            "epoch 287/500 | total error=-0.0007685484921024794\n",
            "epoch 288/500 | total error=-0.0007600168185144441\n",
            "epoch 289/500 | total error=-0.0007500001678568736\n",
            "epoch 290/500 | total error=-0.0007049661669514959\n",
            "epoch 291/500 | total error=-0.0007110638614838252\n",
            "epoch 292/500 | total error=-0.0006930894755177887\n",
            "epoch 293/500 | total error=-0.0006754189405637534\n",
            "epoch 294/500 | total error=-0.0006591260290490925\n",
            "epoch 295/500 | total error=-0.0006414435340204222\n",
            "epoch 296/500 | total error=-0.0006283367149972775\n",
            "epoch 297/500 | total error=-0.0006167065642080555\n",
            "epoch 298/500 | total error=-0.0006172449066782865\n",
            "epoch 299/500 | total error=-0.0006165446159801896\n",
            "epoch 300/500 | total error=-0.000617364728211265\n",
            "epoch 301/500 | total error=-0.0006168545520217276\n",
            "epoch 302/500 | total error=-0.0006178006389966739\n",
            "epoch 303/500 | total error=-0.0006174056387759036\n",
            "epoch 304/500 | total error=-0.0006184117287729426\n",
            "epoch 305/500 | total error=-0.0006180806817859351\n",
            "epoch 306/500 | total error=-0.0006181722198303295\n",
            "epoch 307/500 | total error=-0.0006194422664583274\n",
            "epoch 308/500 | total error=-0.000619257999531309\n",
            "epoch 309/500 | total error=-0.0006131841615358887\n",
            "epoch 310/500 | total error=-0.0006096515185985985\n",
            "epoch 311/500 | total error=-0.0006057967843723447\n",
            "epoch 312/500 | total error=-0.0006031179145482898\n",
            "epoch 313/500 | total error=-0.00060130477164918\n",
            "epoch 314/500 | total error=-0.0006009200395818091\n",
            "epoch 315/500 | total error=-0.0005994830134811738\n",
            "epoch 316/500 | total error=-0.0005986294899470019\n",
            "epoch 317/500 | total error=-0.0005981852440188824\n",
            "epoch 318/500 | total error=-0.0005987869025821695\n",
            "epoch 319/500 | total error=-0.0005981375785979436\n",
            "epoch 320/500 | total error=-0.000597869950242046\n",
            "epoch 321/500 | total error=-0.0005978577828769392\n",
            "epoch 322/500 | total error=-0.0005979684410751816\n",
            "epoch 323/500 | total error=-0.0005981359446135484\n",
            "epoch 324/500 | total error=-0.0005991016944940452\n",
            "epoch 325/500 | total error=-0.0005987665293953455\n",
            "epoch 326/500 | total error=-0.0005986877309134844\n",
            "epoch 327/500 | total error=-0.0005988097469599285\n",
            "epoch 328/500 | total error=-0.0005990145847684491\n",
            "epoch 329/500 | total error=-0.0005992540785150236\n",
            "epoch 330/500 | total error=-0.0005995013477296863\n",
            "epoch 331/500 | total error=-0.0005997445994217421\n",
            "epoch 332/500 | total error=-0.0005999798434017898\n",
            "epoch 333/500 | total error=-0.0006002063906414371\n",
            "epoch 334/500 | total error=-0.0006004247808672308\n",
            "epoch 335/500 | total error=-0.0006006359039113997\n",
            "epoch 336/500 | total error=-0.0006008406553572821\n",
            "epoch 337/500 | total error=-0.0006010398201565564\n",
            "epoch 338/500 | total error=-0.0006012340486451697\n",
            "epoch 339/500 | total error=-0.0006014238667051664\n",
            "epoch 340/500 | total error=-0.0006016096959052156\n",
            "epoch 341/500 | total error=-0.0006017918741910275\n",
            "epoch 342/500 | total error=-0.0006019706739142113\n",
            "epoch 343/500 | total error=-0.0006021463165010077\n",
            "epoch 344/500 | total error=-0.0005925040325140397\n",
            "epoch 345/500 | total error=-0.0005850717618657487\n",
            "epoch 346/500 | total error=-0.0005824977003044165\n",
            "epoch 347/500 | total error=-0.0005804769413911316\n",
            "epoch 348/500 | total error=-0.0005789510025673457\n",
            "epoch 349/500 | total error=-0.0005778138017829927\n",
            "epoch 350/500 | total error=-0.0005769738765008082\n",
            "epoch 351/500 | total error=-0.0005763587947786741\n",
            "epoch 352/500 | total error=-0.0005759128382083599\n",
            "epoch 353/500 | total error=-0.000575593711454025\n",
            "epoch 354/500 | total error=-0.0005753695330543587\n",
            "epoch 355/500 | total error=-0.0005752163658059551\n",
            "epoch 356/500 | total error=-0.0005751162778776785\n",
            "epoch 357/500 | total error=-0.0005750558537614674\n",
            "epoch 358/500 | total error=-0.0005750250642350237\n",
            "epoch 359/500 | total error=-0.000575016414519606\n",
            "epoch 360/500 | total error=-0.0005750243046380045\n",
            "epoch 361/500 | total error=-0.0005750445502168464\n",
            "epoch 362/500 | total error=-0.0005750740239913127\n",
            "epoch 363/500 | total error=-0.0005751103878472677\n",
            "epoch 364/500 | total error=-0.000575151892654337\n",
            "epoch 365/500 | total error=-0.0005751972288030731\n",
            "epoch 366/500 | total error=-0.0005752454146388508\n",
            "epoch 367/500 | total error=-0.0005752957132066197\n",
            "epoch 368/500 | total error=-0.000575347570137375\n",
            "epoch 369/500 | total error=-0.0005754005673182007\n",
            "epoch 370/500 | total error=-0.0005754543883424326\n",
            "epoch 371/500 | total error=-0.0005755087927501191\n",
            "epoch 372/500 | total error=-0.0005755635968260824\n",
            "epoch 373/500 | total error=-0.0005756186592889248\n",
            "epoch 374/500 | total error=-0.0005756738706270717\n",
            "epoch 375/500 | total error=-0.0005757291451537201\n",
            "epoch 376/500 | total error=-0.0005757844150880278\n",
            "epoch 377/500 | total error=-0.0005758396261462649\n",
            "epoch 378/500 | total error=-0.0005758988810273754\n",
            "epoch 379/500 | total error=-0.0005759622629704403\n",
            "epoch 380/500 | total error=-0.0005760270498428554\n",
            "epoch 381/500 | total error=-0.0005732917340554093\n",
            "epoch 382/500 | total error=-0.0005741356722631264\n",
            "epoch 383/500 | total error=-0.0005747144553813361\n",
            "epoch 384/500 | total error=-0.0005751486285345176\n",
            "epoch 385/500 | total error=-0.0005726977563469759\n",
            "epoch 386/500 | total error=-0.0005737374579716363\n",
            "epoch 387/500 | total error=-0.0005744617063331627\n",
            "epoch 388/500 | total error=-0.000572229651650876\n",
            "epoch 389/500 | total error=-0.000573418930543218\n",
            "epoch 390/500 | total error=-0.0005714938269066759\n",
            "epoch 391/500 | total error=-0.000572888882514572\n",
            "epoch 392/500 | total error=-0.0005711234175860725\n",
            "epoch 393/500 | total error=-0.0005726282884548618\n",
            "epoch 394/500 | total error=-0.0005709499660216656\n",
            "epoch 395/500 | total error=-0.000572514598388434\n",
            "epoch 396/500 | total error=-0.0005708846916771267\n",
            "epoch 397/500 | total error=-0.0005724829634756332\n",
            "epoch 398/500 | total error=-0.0005663541278935418\n",
            "epoch 399/500 | total error=-0.0005618190540449148\n",
            "epoch 400/500 | total error=-0.0005656234767837862\n",
            "epoch 401/500 | total error=-0.0005612842275374237\n",
            "epoch 402/500 | total error=-0.0005580809901443786\n",
            "epoch 403/500 | total error=-0.0005557200915322586\n",
            "epoch 404/500 | total error=-0.0005539750212283511\n",
            "epoch 405/500 | total error=-0.0005526835437172728\n",
            "epoch 406/500 | total error=-0.0005517263093489273\n",
            "epoch 407/500 | total error=-0.0005510152974945208\n",
            "epoch 408/500 | total error=-0.0005504856844400281\n",
            "epoch 409/500 | total error=-0.0005500898000347004\n",
            "epoch 410/500 | total error=-0.0005497926229710745\n",
            "epoch 411/500 | total error=-0.0005495684381020243\n",
            "epoch 412/500 | total error=-0.0005493983664905307\n",
            "epoch 413/500 | total error=-0.0005492685458727509\n",
            "epoch 414/500 | total error=-0.0005491687930331133\n",
            "epoch 415/500 | total error=-0.0005490916218195834\n",
            "epoch 416/500 | total error=-0.0005490315229099535\n",
            "epoch 417/500 | total error=-0.0005489844358803656\n",
            "epoch 418/500 | total error=-0.000548947362383843\n",
            "epoch 419/500 | total error=-0.0005489180827908807\n",
            "epoch 420/500 | total error=-0.0005488949486476481\n",
            "epoch 421/500 | total error=-0.00054887673067412\n",
            "epoch 422/500 | total error=-0.0005488625074381664\n",
            "epoch 423/500 | total error=-0.0005488517722522565\n",
            "epoch 424/500 | total error=-0.0005488444056462753\n",
            "epoch 425/500 | total error=-0.0005488397535219215\n",
            "epoch 426/500 | total error=-0.0005488373563215735\n",
            "epoch 427/500 | total error=-0.0005488368734730844\n",
            "epoch 428/500 | total error=-0.0005488380437037897\n",
            "epoch 429/500 | total error=-0.0005488406627679695\n",
            "epoch 430/500 | total error=-0.0005488445683241583\n",
            "epoch 431/500 | total error=-0.0005488496291275664\n",
            "epoch 432/500 | total error=-0.0005488557371895174\n",
            "epoch 433/500 | total error=-0.0005488628020525726\n",
            "epoch 434/500 | total error=-0.000548870746593213\n",
            "epoch 435/500 | total error=-0.0005488795039341534\n",
            "epoch 436/500 | total error=-0.0005488890151657121\n",
            "epoch 437/500 | total error=-0.0005488992276585908\n",
            "epoch 438/500 | total error=-0.0005489100938098293\n",
            "epoch 439/500 | total error=-0.0005489215701065164\n",
            "epoch 440/500 | total error=-0.0005489336164229286\n",
            "epoch 441/500 | total error=-0.000548946195489335\n",
            "epoch 442/500 | total error=-0.0005489592724871792\n",
            "epoch 443/500 | total error=-0.0005489728147376967\n",
            "epoch 444/500 | total error=-0.0005489867914593763\n",
            "epoch 445/500 | total error=-0.0005490011735766348\n",
            "epoch 446/500 | total error=-0.0005490159335665008\n",
            "epoch 447/500 | total error=-0.0005490310453336709\n",
            "epoch 448/500 | total error=-0.0005490464841068919\n",
            "epoch 449/500 | total error=-0.000549062226351428\n",
            "epoch 450/500 | total error=-0.0005490782496937774\n",
            "epoch 451/500 | total error=-0.0005490945328558389\n",
            "epoch 452/500 | total error=-0.0005491110555963817\n",
            "epoch 453/500 | total error=-0.0005491277986583151\n",
            "epoch 454/500 | total error=-0.0005491447437205627\n",
            "epoch 455/500 | total error=-0.0005491618733537124\n",
            "epoch 456/500 | total error=-0.0005491791709788127\n",
            "epoch 457/500 | total error=-0.0005491966208287597\n",
            "epoch 458/500 | total error=-0.0005492142079120051\n",
            "epoch 459/500 | total error=-0.0005492319179781605\n",
            "epoch 460/500 | total error=-0.0005492497374854712\n",
            "epoch 461/500 | total error=-0.0005492676535697824\n",
            "epoch 462/500 | total error=-0.0005492856540150943\n",
            "epoch 463/500 | total error=-0.00054930372722526\n",
            "epoch 464/500 | total error=-0.0005493218621971076\n",
            "epoch 465/500 | total error=-0.0005493400484946597\n",
            "epoch 466/500 | total error=-0.0005470365732429679\n",
            "epoch 467/500 | total error=-0.0005477195912584796\n",
            "epoch 468/500 | total error=-0.0005481751353652069\n",
            "epoch 469/500 | total error=-0.0005462006788698845\n",
            "epoch 470/500 | total error=-0.00054710712048309\n",
            "epoch 471/500 | total error=-0.0005454346052310274\n",
            "epoch 472/500 | total error=-0.0005465429644671128\n",
            "epoch 473/500 | total error=-0.0005450262494720795\n",
            "epoch 474/500 | total error=-0.0005462406490632167\n",
            "epoch 475/500 | total error=-0.0005448076991625823\n",
            "epoch 476/500 | total error=-0.0005460786953387398\n",
            "epoch 477/500 | total error=-0.0005446916925472736\n",
            "epoch 478/500 | total error=-0.0005437335704145395\n",
            "epoch 479/500 | total error=-0.0005452904432752271\n",
            "epoch 480/500 | total error=-0.0005441203432377748\n",
            "epoch 481/500 | total error=-0.0005433180371844112\n",
            "epoch 482/500 | total error=-0.0005427399541950173\n",
            "epoch 483/500 | total error=-0.0005445519497914262\n",
            "epoch 484/500 | total error=-0.000543581807714894\n",
            "epoch 485/500 | total error=-0.0005429245314732426\n",
            "epoch 486/500 | total error=-0.0005424223477078454\n",
            "epoch 487/500 | total error=-0.000542059411025312\n",
            "epoch 488/500 | total error=-0.0005418000777439438\n",
            "epoch 489/500 | total error=-0.0005416137042377682\n",
            "epoch 490/500 | total error=-0.0005414786521767286\n",
            "epoch 491/500 | total error=-0.0005413800130813622\n",
            "epoch 492/500 | total error=-0.0005329330019275848\n",
            "epoch 493/500 | total error=-0.0005368745830566403\n",
            "epoch 494/500 | total error=-0.0005400783610500856\n",
            "epoch 495/500 | total error=-0.0005318981298176355\n",
            "epoch 496/500 | total error=-0.0005360593894672744\n",
            "epoch 497/500 | total error=-0.0005394431611689515\n",
            "epoch 498/500 | total error=-0.000531426228335783\n",
            "epoch 499/500 | total error=-0.0005356882346091821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#precisión alcanzada con los datos de entrenamiento\n",
        "accuracy = net.accuracy(examples)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "FLxCnkvMm9Kp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8509004b-4ed9-4500-c7fe-73f16fe62cc3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#precisión alcanzada con los datos de prueba\n",
        "examples = []\n",
        "for i in range(len(X_test)):\n",
        "    examples.append([X_test[i], y_test[i]])\n",
        "accuracy = net.accuracy(examples)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "35AyCvCmm_96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf3bdaf9-ec50-48f0-9541-fb8f1c7f0fe0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#probando con un dato\n",
        "prediction = net.predict(X_test[2])\n",
        "print(f\"Desired output: {y_test[2]}\")\n",
        "print(f\"Index of output: {prediction}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGMT3cV2ocL2",
        "outputId": "8bb2745e-d0c9-4ba0-a23d-0ba50623d209"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Desired output: [1. 0. 0.]\n",
            "Index of output: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modificación de la implementación de la red neuronal"
      ],
      "metadata": {
        "id": "M8-mcDfFprEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import graphviz\n",
        "\n",
        "def draw_graph(net):\n",
        "    dot = graphviz.Digraph()\n",
        "    dot.attr('node', shape='circle')\n",
        "    for i, layer in enumerate(net.net):\n",
        "        with dot.subgraph(name=f'cluster_{i}') as c:\n",
        "            c.attr(style='invis')\n",
        "            for j, node in enumerate(layer):\n",
        "                c.node(f'{i},{j}')\n",
        "    for i, layer in enumerate(net.net):\n",
        "        for j, node in enumerate(layer):\n",
        "            for input_node, weight in zip(node.inputs, node.weights):\n",
        "                dot.edge(f'{i-1},{net.net[i-1].index(input_node)}', f'{i},{j}', label=f'{weight:.2f}')\n",
        "    return dot\n",
        "    \n",
        "draw_graph(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "NMbTaqXTcwDU",
        "outputId": "71567e0e-165c-4bc5-db02-ce436baa71ec"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7fbd995e8fd0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"552pt\" height=\"275pt\"\n viewBox=\"0.00 0.00 552.01 274.59\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 270.59)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-270.59 548.01,-270.59 548.01,4 -4,4\"/>\n<g id=\"clust1\" class=\"cluster\">\n<title>cluster_0</title>\n</g>\n<g id=\"clust2\" class=\"cluster\">\n<title>cluster_1</title>\n</g>\n<g id=\"clust3\" class=\"cluster\">\n<title>cluster_2</title>\n</g>\n<!-- 0,0 -->\n<g id=\"node1\" class=\"node\">\n<title>0,0</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"226.01\" cy=\"-228.49\" rx=\"22.2\" ry=\"22.2\"/>\n<text text-anchor=\"middle\" x=\"226.01\" y=\"-224.79\" font-family=\"Times,serif\" font-size=\"14.00\">0,0</text>\n</g>\n<!-- 1,0 -->\n<g id=\"node4\" class=\"node\">\n<title>1,0</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"371.01\" cy=\"-133.29\" rx=\"22.2\" ry=\"22.2\"/>\n<text text-anchor=\"middle\" x=\"371.01\" y=\"-129.59\" font-family=\"Times,serif\" font-size=\"14.00\">1,0</text>\n</g>\n<!-- 0,0&#45;&gt;1,0 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0,0&#45;&gt;1,0</title>\n<path fill=\"none\" stroke=\"black\" d=\"M239.63,-211.01C244.58,-206.13 250.55,-201.31 257.01,-198.39 278.58,-188.66 345.84,-204.68 363.01,-188.39 369.23,-182.49 372.06,-174.03 373.11,-165.54\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"376.62,-165.5 373.63,-155.34 369.63,-165.15 376.62,-165.5\"/>\n<text text-anchor=\"middle\" x=\"383.51\" y=\"-177.19\" font-family=\"Times,serif\" font-size=\"14.00\">0.10</text>\n</g>\n<!-- 1,1 -->\n<g id=\"node5\" class=\"node\">\n<title>1,1</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"309.01\" cy=\"-133.29\" rx=\"22.2\" ry=\"22.2\"/>\n<text text-anchor=\"middle\" x=\"309.01\" y=\"-129.59\" font-family=\"Times,serif\" font-size=\"14.00\">1,1</text>\n</g>\n<!-- 0,0&#45;&gt;1,1 -->\n<g id=\"edge4\" class=\"edge\">\n<title>0,0&#45;&gt;1,1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M236.77,-209.03C243.72,-197.98 253.42,-184.07 264.01,-173.39 269.4,-167.96 272.1,-168.24 278.01,-163.39 280.63,-161.24 283.32,-158.92 285.95,-156.56\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"288.62,-158.86 293.61,-149.52 283.88,-153.71 288.62,-158.86\"/>\n<text text-anchor=\"middle\" x=\"276.51\" y=\"-177.19\" font-family=\"Times,serif\" font-size=\"14.00\">0.10</text>\n</g>\n<!-- 1,2 -->\n<g id=\"node6\" class=\"node\">\n<title>1,2</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"185.01\" cy=\"-133.29\" rx=\"22.2\" ry=\"22.2\"/>\n<text text-anchor=\"middle\" x=\"185.01\" y=\"-129.59\" font-family=\"Times,serif\" font-size=\"14.00\">1,2</text>\n</g>\n<!-- 0,0&#45;&gt;1,2 -->\n<g id=\"edge7\" class=\"edge\">\n<title>0,0&#45;&gt;1,2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M203.96,-226.97C153.65,-225.27 32.87,-218.1 8.01,-188.39 -32.06,-140.5 90.7,-134.14 152.17,-133.86\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"152.53,-137.36 162.53,-133.87 152.53,-130.36 152.53,-137.36\"/>\n<text text-anchor=\"middle\" x=\"20.51\" y=\"-177.19\" font-family=\"Times,serif\" font-size=\"14.00\">0.10</text>\n</g>\n<!-- 1,3 -->\n<g id=\"node7\" class=\"node\">\n<title>1,3</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"247.01\" cy=\"-133.29\" rx=\"22.2\" ry=\"22.2\"/>\n<text text-anchor=\"middle\" x=\"247.01\" y=\"-129.59\" font-family=\"Times,serif\" font-size=\"14.00\">1,3</text>\n</g>\n<!-- 0,0&#45;&gt;1,3 -->\n<g id=\"edge10\" class=\"edge\">\n<title>0,0&#45;&gt;1,3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M203.99,-225.49C161.16,-220.81 73.36,-206.9 104.01,-173.39 120.87,-154.95 193.21,-173.61 216.01,-163.39 219.44,-161.85 222.74,-159.77 225.82,-157.43\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"228.18,-160.01 233.4,-150.79 223.57,-154.74 228.18,-160.01\"/>\n<text text-anchor=\"middle\" x=\"116.51\" y=\"-177.19\" font-family=\"Times,serif\" font-size=\"14.00\">0.10</text>\n</g>\n<!-- 0,1 -->\n<g id=\"node2\" class=\"node\">\n<title>0,1</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"288.01\" cy=\"-228.49\" rx=\"22.2\" ry=\"22.2\"/>\n<text text-anchor=\"middle\" x=\"288.01\" y=\"-224.79\" font-family=\"Times,serif\" font-size=\"14.00\">0,1</text>\n</g>\n<!-- 0,1&#45;&gt;1,0 -->\n<g id=\"edge2\" class=\"edge\">\n<title>0,1&#45;&gt;1,0</title>\n<path fill=\"none\" stroke=\"black\" d=\"M301.64,-211.04C306.59,-206.16 312.56,-201.33 319.01,-198.39 338.93,-189.31 402.34,-204.64 417.01,-188.39 428.37,-175.81 414.25,-161.13 398.75,-150.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"400.43,-147.16 390.14,-144.62 396.6,-153.02 400.43,-147.16\"/>\n<text text-anchor=\"middle\" x=\"433.51\" y=\"-177.19\" font-family=\"Times,serif\" font-size=\"14.00\">0.20</text>\n</g>\n<!-- 0,1&#45;&gt;1,1 -->\n<g id=\"edge5\" class=\"edge\">\n<title>0,1&#45;&gt;1,1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M290.28,-206.26C291.58,-196.22 293.46,-184.11 296.01,-173.39 296.73,-170.36 297.59,-167.22 298.5,-164.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"301.9,-164.98 301.58,-154.39 295.23,-162.87 301.9,-164.98\"/>\n<text text-anchor=\"middle\" x=\"308.51\" y=\"-177.19\" font-family=\"Times,serif\" font-size=\"14.00\">0.20</text>\n</g>\n<!-- 0,1&#45;&gt;1,2 -->\n<g id=\"edge8\" class=\"edge\">\n<title>0,1&#45;&gt;1,2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M274.46,-210.86C269.52,-205.96 263.53,-201.17 257.01,-198.39 237.77,-190.18 83.4,-203.57 69.01,-188.39 41.54,-159.42 109.78,-144.47 152.91,-138.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"153.57,-141.57 162.99,-136.73 152.61,-134.63 153.57,-141.57\"/>\n<text text-anchor=\"middle\" x=\"81.51\" y=\"-177.19\" font-family=\"Times,serif\" font-size=\"14.00\">0.20</text>\n</g>\n<!-- 0,1&#45;&gt;1,3 -->\n<g id=\"edge11\" class=\"edge\">\n<title>0,1&#45;&gt;1,3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M274.39,-211.02C269.44,-206.13 263.47,-201.31 257.01,-198.39 235.65,-188.74 167.78,-205.73 152.01,-188.39 147.52,-183.46 147.67,-178.46 152.01,-173.39 170.73,-151.52 190.14,-176.03 216.01,-163.39 219.22,-161.82 222.33,-159.8 225.26,-157.56\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"227.73,-160.05 232.97,-150.85 223.13,-154.78 227.73,-160.05\"/>\n<text text-anchor=\"middle\" x=\"164.51\" y=\"-177.19\" font-family=\"Times,serif\" font-size=\"14.00\">0.20</text>\n</g>\n<!-- 0,2 -->\n<g id=\"node3\" class=\"node\">\n<title>0,2</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"350.01\" cy=\"-228.49\" rx=\"22.2\" ry=\"22.2\"/>\n<text text-anchor=\"middle\" x=\"350.01\" y=\"-224.79\" font-family=\"Times,serif\" font-size=\"14.00\">0,2</text>\n</g>\n<!-- 0,2&#45;&gt;1,0 -->\n<g id=\"edge3\" class=\"edge\">\n<title>0,2&#45;&gt;1,0</title>\n<path fill=\"none\" stroke=\"black\" d=\"M371.92,-225.53C412.24,-221.41 495.67,-210.39 513.01,-188.39 543.51,-149.71 453.98,-138.68 403.28,-135.54\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"403.29,-132.03 393.11,-134.98 402.9,-139.02 403.29,-132.03\"/>\n<text text-anchor=\"middle\" x=\"531.51\" y=\"-177.19\" font-family=\"Times,serif\" font-size=\"14.00\">0.30</text>\n</g>\n<!-- 0,2&#45;&gt;1,1 -->\n<g id=\"edge6\" class=\"edge\">\n<title>0,2&#45;&gt;1,1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M372.09,-225.04C413.03,-219.69 494.04,-204.84 465.01,-173.39 446.11,-152.92 365.49,-174.67 340.01,-163.39 336.57,-161.87 333.27,-159.8 330.19,-157.46\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"332.44,-154.78 322.61,-150.82 327.83,-160.04 332.44,-154.78\"/>\n<text text-anchor=\"middle\" x=\"483.51\" y=\"-177.19\" font-family=\"Times,serif\" font-size=\"14.00\">0.30</text>\n</g>\n<!-- 0,2&#45;&gt;1,2 -->\n<g id=\"edge9\" class=\"edge\">\n<title>0,2&#45;&gt;1,2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M336.37,-211.05C331.42,-206.17 325.45,-201.34 319.01,-198.39 280,-180.56 260,-210.12 223.01,-188.39 212.78,-182.38 204.62,-172.41 198.52,-162.65\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"201.5,-160.81 193.5,-153.87 195.42,-164.29 201.5,-160.81\"/>\n<text text-anchor=\"middle\" x=\"235.51\" y=\"-177.19\" font-family=\"Times,serif\" font-size=\"14.00\">0.30</text>\n</g>\n<!-- 0,2&#45;&gt;1,3 -->\n<g id=\"edge12\" class=\"edge\">\n<title>0,2&#45;&gt;1,3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M343.84,-207.2C339.31,-195.63 332.01,-181.82 321.01,-173.39 305.43,-161.46 295.31,-172.65 278.01,-163.39 274.85,-161.7 271.78,-159.61 268.88,-157.33\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"271.01,-154.55 261.19,-150.57 266.39,-159.8 271.01,-154.55\"/>\n<text text-anchor=\"middle\" x=\"346.51\" y=\"-177.19\" font-family=\"Times,serif\" font-size=\"14.00\">0.30</text>\n</g>\n<!-- 2,0 -->\n<g id=\"node8\" class=\"node\">\n<title>2,0</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"178.01\" cy=\"-38.1\" rx=\"22.2\" ry=\"22.2\"/>\n<text text-anchor=\"middle\" x=\"178.01\" y=\"-34.4\" font-family=\"Times,serif\" font-size=\"14.00\">2,0</text>\n</g>\n<!-- 1,0&#45;&gt;2,0 -->\n<g id=\"edge13\" class=\"edge\">\n<title>1,0&#45;&gt;2,0</title>\n<path fill=\"none\" stroke=\"black\" d=\"M358.09,-114.96C347.69,-102.43 331.89,-86.33 314.01,-78.2 271.34,-58.78 251.73,-87.5 209.01,-68.2 205.58,-66.65 202.28,-64.56 199.21,-62.21\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"201.46,-59.53 191.63,-55.57 196.85,-64.79 201.46,-59.53\"/>\n<text text-anchor=\"middle\" x=\"347.51\" y=\"-82\" font-family=\"Times,serif\" font-size=\"14.00\">0.50</text>\n</g>\n<!-- 2,1 -->\n<g id=\"node9\" class=\"node\">\n<title>2,1</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"240.01\" cy=\"-38.1\" rx=\"22.2\" ry=\"22.2\"/>\n<text text-anchor=\"middle\" x=\"240.01\" y=\"-34.4\" font-family=\"Times,serif\" font-size=\"14.00\">2,1</text>\n</g>\n<!-- 1,0&#45;&gt;2,1 -->\n<g id=\"edge17\" class=\"edge\">\n<title>1,0&#45;&gt;2,1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M384.75,-115.34C392.23,-103.94 398.41,-89.07 390.01,-78.2 375.7,-59.67 311.58,-48.27 271.94,-42.86\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"272.33,-39.39 261.96,-41.56 271.42,-46.33 272.33,-39.39\"/>\n<text text-anchor=\"middle\" x=\"406.51\" y=\"-82\" font-family=\"Times,serif\" font-size=\"14.00\">0.60</text>\n</g>\n<!-- 1,1&#45;&gt;2,0 -->\n<g id=\"edge14\" class=\"edge\">\n<title>1,1&#45;&gt;2,0</title>\n<path fill=\"none\" stroke=\"black\" d=\"M295.37,-115.85C290.43,-110.97 284.46,-106.14 278.01,-103.2 258.3,-94.2 195.97,-108.88 181.01,-93.2 175.15,-87.05 173.05,-78.51 172.79,-70.03\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"176.29,-70.03 173.25,-59.88 169.3,-69.71 176.29,-70.03\"/>\n<text text-anchor=\"middle\" x=\"193.51\" y=\"-82\" font-family=\"Times,serif\" font-size=\"14.00\">0.50</text>\n</g>\n<!-- 1,1&#45;&gt;2,1 -->\n<g id=\"edge18\" class=\"edge\">\n<title>1,1&#45;&gt;2,1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M298.42,-113.75C292.05,-103.06 283.55,-89.54 275.01,-78.2 270.98,-72.85 266.38,-67.35 261.87,-62.22\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"264.25,-59.63 254.95,-54.56 259.05,-64.33 264.25,-59.63\"/>\n<text text-anchor=\"middle\" x=\"297.51\" y=\"-82\" font-family=\"Times,serif\" font-size=\"14.00\">0.60</text>\n</g>\n<!-- 1,2&#45;&gt;2,0 -->\n<g id=\"edge15\" class=\"edge\">\n<title>1,2&#45;&gt;2,0</title>\n<path fill=\"none\" stroke=\"black\" d=\"M162.77,-131.38C137.23,-128.99 96.36,-120.78 77.01,-93.2 57.41,-65.26 109.44,-50.47 145.9,-43.75\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"146.89,-47.13 156.16,-42 145.71,-40.24 146.89,-47.13\"/>\n<text text-anchor=\"middle\" x=\"89.51\" y=\"-82\" font-family=\"Times,serif\" font-size=\"14.00\">0.50</text>\n</g>\n<!-- 1,2&#45;&gt;2,1 -->\n<g id=\"edge19\" class=\"edge\">\n<title>1,2&#45;&gt;2,1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M195.88,-113.88C203.86,-100.35 214.84,-81.74 223.85,-66.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"227.1,-67.86 229.17,-57.47 221.07,-64.31 227.1,-67.86\"/>\n<text text-anchor=\"middle\" x=\"228.51\" y=\"-82\" font-family=\"Times,serif\" font-size=\"14.00\">0.60</text>\n</g>\n<!-- 1,3&#45;&gt;2,0 -->\n<g id=\"edge16\" class=\"edge\">\n<title>1,3&#45;&gt;2,0</title>\n<path fill=\"none\" stroke=\"black\" d=\"M233.36,-115.88C228.41,-110.99 222.45,-106.16 216.01,-103.2 197.53,-94.69 138.59,-108.35 125.01,-93.2 112.42,-79.14 130.6,-63.84 149.01,-53.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"150.84,-56.1 157.93,-48.24 147.48,-49.96 150.84,-56.1\"/>\n<text text-anchor=\"middle\" x=\"137.51\" y=\"-82\" font-family=\"Times,serif\" font-size=\"14.00\">0.50</text>\n</g>\n<!-- 1,3&#45;&gt;2,1 -->\n<g id=\"edge20\" class=\"edge\">\n<title>1,3&#45;&gt;2,1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M247.27,-111.19C247.23,-101.18 246.94,-89.05 246.01,-78.2 245.79,-75.62 245.5,-72.96 245.18,-70.29\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"248.61,-69.56 243.77,-60.14 241.68,-70.53 248.61,-69.56\"/>\n<text text-anchor=\"middle\" x=\"258.51\" y=\"-82\" font-family=\"Times,serif\" font-size=\"14.00\">0.60</text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* agrega el método weigths() a la clase Network, de tal forma que permita obtener los pesos de las neuronas"
      ],
      "metadata": {
        "id": "RvT8ovoFeeVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = net.weights()\n",
        "\n",
        "for i, layer in enumerate(weights):\n",
        "    print(f\"Node {i} weights: {layer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p56f39VVaooU",
        "outputId": "6f961176-b611-4ae0-b193-399e905b8531"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node 0 weights: []\n",
            "Node 1 weights: []\n",
            "Node 2 weights: []\n",
            "Node 3 weights: [0.1, 0.2, 0.3]\n",
            "Node 4 weights: [0.1, 0.2, 0.3]\n",
            "Node 5 weights: [0.1, 0.2, 0.3]\n",
            "Node 6 weights: [0.1, 0.2, 0.3]\n",
            "Node 7 weights: [0.5, 0.5, 0.5, 0.5]\n",
            "Node 8 weights: [0.6, 0.6, 0.6, 0.6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* agrega el método set_weights() a la clase Network, de tal forma que permite definir los pesos de las neuronas"
      ],
      "metadata": {
        "id": "pokp7ZDJemrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_weights = [\n",
        "    [\n",
        "        [],\n",
        "        [],\n",
        "        []\n",
        "    ],\n",
        "    [\n",
        "        [0.1, 0.2, 0.3],\n",
        "        [0.1, 0.2, 0.3],\n",
        "        [0.1, 0.2, 0.3],\n",
        "        [0.1, 0.2, 0.3]\n",
        "    ],\n",
        "    [\n",
        "        [0.5, 0.5, 0.5, 0.5],\n",
        "        [0.6, 0.6, 0.6, 0.6]\n",
        "    ], \n",
        "]\n",
        "\n",
        "# Establecer los nuevos pesos en la red neuronal\n",
        "net.set_weights(new_weights)"
      ],
      "metadata": {
        "id": "YY3sFDs2ebZE"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# modifica la clase Network, para que se pueda decidir qué función de activación utilizar: relu() o sigmoide() EN LA RETROPROPAGACION HABRIA QUE UTILIZAR EL PRIME"
      ],
      "metadata": {
        "id": "Yg3ScNjfq_ot"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# los métodos predict() y accuracy() de la clase Network están implementados para resolver problemas de clasificación\n",
        "# modifícalos de tal manera que también se puedan utilizar con problemas de regresión"
      ],
      "metadata": {
        "id": "XUYfTnwwtAP3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# modifica el método backpropagation() de tal manera que devuelva como resultado el array de valores de los nodos durante las épocas de entrenamiento"
      ],
      "metadata": {
        "id": "_jcNyPgK0Jdm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# una vez implementados los cambios, entrena la red neuronal del ejemplo de los apuntes\n",
        "examples = []\n",
        "examples.append([[0.5, 0.67, 0.5], [0.25, 0.6]])"
      ],
      "metadata": {
        "id": "ROQGXdl8uNXc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ejecuta la red neuronal para los datos de ejemplo de los apuntes\n",
        "# comprueba los valores de los nodos y de los pesos\n",
        "# los valores de los nodos tienen que ser los mismos que los de los apuntes\n",
        "# los valores de los pesos son ligeramente diferentes, ¿por qué?\n",
        "\n",
        "net = Network([3, 4, 2])\n",
        "\n",
        "net.set_weights([0.1, 0.2, 0.3, 0.4, 0.5, 0.6])\n",
        "# o\n",
        "net.set_weights([[0.1, 0.1, 0.1], [0.2, 0.2, 0.2], [0.3, 0.3, 0.3], [0.4, 0.4, 0.4], [0.5, 0.5, 0.5, 0.5], [0.6, 0.6, 0.6, 0.6]])\n",
        "\n",
        "valores_nodos = net.backpropagation(0.9, examples, 1)\n",
        "\n",
        "print(valores_nodos)\n",
        "net.weights()"
      ],
      "metadata": {
        "id": "Q-0NYrsYu2nH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "f0137565-fea1-4b4b-c345-2949d268753e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-7ddc60ecbf79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# o\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-ad55ac8f4a6e>\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Número de capas no coincide\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Número de capas no coincide"
          ]
        }
      ]
    }
  ]
}